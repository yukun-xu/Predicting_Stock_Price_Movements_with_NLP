{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chenwi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chenwi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chenwi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import urllib.request\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import locale\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from pandas_datareader import data as web\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetStockPrice(stock, startDate, endDate, method):\n",
    "    if method == 0:\n",
    "        Stockdf = web.DataReader(stock, 'yahoo', startDate, endDate)\n",
    "        AdjClosedf = pd.DataFrame(Stockdf['Adj Close'])\n",
    "        AdjClosedf.loc[:,'Label'] = (AdjClosedf['Adj Close'].pct_change()>0).astype(int)\n",
    "\n",
    "    else:\n",
    "        page = urllib.request.urlopen('https://finance.yahoo.com/quote/'+stock+'/history?period1=1474095600&period2=1504249200&interval=1d&filter=history&frequency=1d').read()\n",
    "        soup = BeautifulSoup(page, 'html5lib')\n",
    "        snap = soup.find(\"table\", class_=\"W(100%) M(0)\")\n",
    "        snap_body = snap.find('tbody')\n",
    "        rows = snap_body.find_all('tr')\n",
    "\n",
    "        #print \"Number of data: %d\\n\" % (len(rows))\n",
    "        Datelist = []\n",
    "        AdjCloselist = []\n",
    "\n",
    "        for element in rows:\n",
    "            s = element.find_all(\"span\")\n",
    "            if len(s) == 7:\n",
    "                Datelist.append(datetime.strptime(s[0].get_text(), '%b %d, %Y'))\n",
    "                AdjCloselist.append(locale.atof(s[5].get_text().replace(',','')))\n",
    "\n",
    "\n",
    "        AdjClosedf = pd.DataFrame(AdjCloselist,columns=[stock],index = Datelist)\n",
    "        #print(AdjClosedf.columns)\n",
    "        AdjClosedf = AdjClosedf.sort_index()\n",
    "        AdjClosedf.rename(columns={stock: 'Adj Close'}, inplace=True)\n",
    "        AdjClosedf.loc[:,'Label'] = (AdjClosedf['Adj Close'].pct_change()>0).astype(int)\n",
    "        \n",
    "    return AdjClosedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetStockNews(stock, TopN, DateRange):\n",
    "    data = {}\n",
    "    for ndate in DateRange:\n",
    "        data[ndate] = []\n",
    "        #print ndate.strftime('%Y-%m-%d')\n",
    "        startdate = ndate.strftime('%Y-%m-%d')\n",
    "        enddate = startdate\n",
    "        page = urllib.request.urlopen('https://finance.google.com/finance/company_news?q=NASDAQ%3A'+stock+\n",
    "                                      '&startdate='+startdate+'&enddate='+enddate).read()\n",
    "        soup= BeautifulSoup(page, 'html5lib')\n",
    "        news = soup.find_all(\"div\", class_=\"g-section news sfe-break-bottom-16\")\n",
    "        #print (\"Number of news: %d\\n\" % (len(news)))\n",
    "        for element in news[:TopN]:\n",
    "            t = element.find_all(\"span\", class_=\"name\")[0].get_text().replace('\\xa0',' ').replace('\\n','')#.encode('utf-8')\n",
    "            #print t \n",
    "            data[ndate].append(t)\n",
    "        for i in range(0,TopN - len(news),1):\n",
    "            data[ndate].append('')\n",
    "    df = pd.DataFrame().from_dict(data).T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = '2015-01-01'\n",
    "end = '2017-09-01'\n",
    "constituentdf = pd.read_csv('constituents.csv',)\n",
    "stocklist = constituentdf.Symbol.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive = pd.read_csv('positive-words.txt', names=['a'], encoding='latin-1')\n",
    "positive =  set(positive['a'].tolist())\n",
    "\n",
    "negative = pd.read_csv('negative-words.txt', names=['a'], encoding='latin-1')\n",
    "negative =  set(negative['a'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addSentiment(newsInput): \n",
    "    commonp = set(newsInput.split()).intersection(positive) \n",
    "    count_positive=len(commonp)\n",
    "    commonn = set(newsInput.split()).intersection(negative) \n",
    "    count_negative=len(commonn)\n",
    "    return count_positive, count_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FilterSentence(headline):\n",
    "    sentence = nltk.word_tokenize(headline)\n",
    "    sent = nltk.pos_tag(sentence)\n",
    "    tempfiltered_words = [s[0] for s in sent if s[1][0] in ['J','V','N']]\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    exclude = set(string.punctuation+'‘’“”0123456789')\n",
    "    filtered_words = ' '.join(word.lower() for word in tempfiltered_words if (word not in stops) and (word not in exclude))\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainingProcess(train):\n",
    "    filtered_words = []\n",
    "    for row in range(0,len(train.index)):\n",
    "        headline = ' '.join(str(x).replace('\\uFFFD','') for x in train.iloc[row,1:])\n",
    "        trainheadlines = FilterSentence(headline)\n",
    "        count_positive, count_negative=addSentiment(trainheadlines)\n",
    "        for i in range(count_positive):\n",
    "            trainheadlines+=' positive'\n",
    "        for j in range(count_negative):\n",
    "            trainheadlines+=' negative'\n",
    "        filtered_words.append(trainheadlines)\n",
    "    \n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LogisticRegression())])\n",
    "    text_clf.fit(filtered_words, train[\"Label\"])\n",
    "    \n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestProcess(test,text_clf):\n",
    "    filtered_words = []\n",
    "    for row in range(0,len(test.index)):\n",
    "        headline = ' '.join(str(x).replace('\\uFFFD','') for x in test.iloc[row,1:])\n",
    "        testheadlines = FilterSentence(headline)\n",
    "        count_positive, count_negative=addSentiment(testheadlines)\n",
    "        for i in range(count_positive):\n",
    "            testheadlines+=' positive'\n",
    "        for j in range(count_negative):\n",
    "            testheadlines+=' negative'\n",
    "        filtered_words.append(testheadlines)\n",
    "\n",
    "    predictions = text_clf.predict(filtered_words)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calScores(y_test, y_test_pred):\n",
    "    print(\"Accuracy score:\")\n",
    "    acc_score = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "    print(\"On test set: %.3f\" % acc_score)\n",
    "    print(\"\\nF1 score:\")\n",
    "    f_score = f1_score(y_true=y_test, y_pred=y_test_pred, average='weighted')                                            \n",
    "    print(\"On test set: %.3f\" % f_score)\n",
    "    crossdf = pd.crosstab(y_test, y_test_pred, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "    print('\\n')\n",
    "    print(crossdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "TopN = 10\n",
    "TrainSize = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datadf = pd.DataFrame()\n",
    "#inputdf = pd.read_csv(stock+'.csv',index_col=0,encoding='utf-8')\n",
    "#datadf = pd.concat([datadf,inputdf],axis = 0)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Label                                                  0  \\\n",
      "2017-04-17      0  Smart Investors Are Already Buying These Stock...   \n",
      "2017-04-18      0  Ann Marie Hanrahan, 3M attorney who championed...   \n",
      "2017-04-19      0  More lucky locals set to share �3m windfall as...   \n",
      "2017-04-20      1  A Retirement Portfolio With Quality Over Quantity   \n",
      "2017-04-21      1  Epson Makes Two Announcements at ISA Expo Enha...   \n",
      "\n",
      "                                                            1  \\\n",
      "2017-04-17  Two Brits arrested in Alicante on �3m drugs tr...   \n",
      "2017-04-18  Global Grinding Machine Market, 2023: Leading ...   \n",
      "2017-04-19  New �3m partnership to help children stay safe...   \n",
      "2017-04-20  Revealed: Kirkcaldy streets set for �3m lotter...   \n",
      "2017-04-21  Ex-Gonzalez Saggio Lawyers in NJ Join NY's Sch...   \n",
      "\n",
      "                                                            2  \\\n",
      "2017-04-17      DWTC attracts more than 3m visitors last year   \n",
      "2017-04-18  Driving Innovation through Responsible Sourcin...   \n",
      "2017-04-19  Officials say company is avoiding Passaic clea...   \n",
      "2017-04-20     Chicago Cubs co-owner won't join Trump Cabinet   \n",
      "2017-04-21  'Armani cocaine smuggler' arrested over 1.1 TO...   \n",
      "\n",
      "                                                            3  \\\n",
      "2017-04-17                Classy Cook steers Essex to victory   \n",
      "2017-04-18  Kluger Kaplan Expands Into Midwest With Parker...   \n",
      "2017-04-19  Market bears resurface, S&P 500 balks at the b...   \n",
      "2017-04-20  Co Armagh concrete firm entered administration...   \n",
      "2017-04-21  Jury Awards $3M to Widow of Ex-Reed Smith Partner   \n",
      "\n",
      "                                                            4  \\\n",
      "2017-04-17                 Yorkshire close in on emphatic win   \n",
      "2017-04-18  DJIA Today: Dow Jones Futures Rise Triple Digi...   \n",
      "2017-04-19  The Arrivals' Sleek Jackets Let You Wear Your ...   \n",
      "2017-04-20  Access Control and Authentication Market Repor...   \n",
      "2017-04-21  EFI Highlights New LED Printers and Productivi...   \n",
      "\n",
      "                                                            5  \\\n",
      "2017-04-17  GMP paid out �6m in compensation and legal cos...   \n",
      "2017-04-18  O'Melveny Lands Foley & Lardner Sports Co-Lead...   \n",
      "2017-04-19  'Proms in Park' event announces support of loc...   \n",
      "2017-04-20    Harman Int'l Settles Stock Drop Saga For $28.3M   \n",
      "2017-04-21  Real Madrid reject Liverpool's �42m bid for Ma...   \n",
      "\n",
      "                                                            6  \\\n",
      "2017-04-17                    Top Cook eases Essex to victory   \n",
      "2017-04-18  Ex-Marlins player Alex Gonzalez sells Weston m...   \n",
      "2017-04-19  'Birds & Bubbles' Sues Forsyth Street Landlord...   \n",
      "2017-04-20  �3m investment in Whitemead Forest Park in For...   \n",
      "2017-04-21            Boswell heads to Agriculture Department   \n",
      "\n",
      "                                                            7  \\\n",
      "2017-04-17  Drones flying into prisons to be examined by n...   \n",
      "2017-04-18                   Lottery sales lagging once again   \n",
      "2017-04-19  Zacks Investment Research Upgrades Twilio Inc ...   \n",
      "2017-04-20       Humaniq Secures $3m in Initial Coin Offering   \n",
      "2017-04-21        Two Hospitalized When Motorcycle Blows Tire   \n",
      "\n",
      "                                                            8  \\\n",
      "2017-04-17  What to watch this week in Rutherford County a...   \n",
      "2017-04-18  East side co-working space with huge bar, 'nap...   \n",
      "2017-04-19  Big budget cuts at game parks will badly hinde...   \n",
      "2017-04-20       Lidl UK chooses NSPCC as its charity partner   \n",
      "2017-04-21  AI, big data and robotics are London's fastest...   \n",
      "\n",
      "                                                            9  \n",
      "2017-04-17  Match preview: Ipswich Town are all but safe, ...  \n",
      "2017-04-18         Title defence starts with hard-fought draw  \n",
      "2017-04-19        Peter Bohlin on Designing the Perfect House  \n",
      "2017-04-20                ASA loses $4.3m, fires top managers  \n",
      "2017-04-21  Get to know fashion blogger Rach Parcell like ...  \n"
     ]
    }
   ],
   "source": [
    "datadf = pd.DataFrame()\n",
    "for stock in stocklist:\n",
    "    if os.path.isfile('.\\Data\\\\'+stock+'.csv'):\n",
    "        #print(stock)\n",
    "        inputdf = pd.read_csv('.\\Data\\\\'+stock+'.csv',index_col=0,encoding='utf_8')\n",
    "        datadf = pd.concat([datadf,inputdf],axis = 0)\n",
    "print(datadf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5773,)\n",
      "Real estate briefly: Digital Map Products shifting HQ to University Research Park JPMorgan Chase & Co. Raises Stake in PICO Holdings Inc. (NASDAQ:PICO) iShares iBoxx $ High Yid Corp Bond (NYSE:HYG) Shares Bought by Sei Investments Co. Alio Gold Inc (NYSE:ALO) Upgraded at BMO Capital Markets PGGM Investments Has $68452000 Stake in Camden Property Trust (CPT) Temperance Flat Dam investment will pay off for California The Charles Schwab Corporation - Receive News & Ratings Daily Digipath Inc. (OTCMKTS:DIGP) Lowered to Sell at ValuEngine Week in review: Health insurers to get rate hikes; developer sentenced to 4 months Hey, Marijuana Stock Investors: This Senator Just Introduced a Bill That ...\n",
      "(5773, 37014)\n"
     ]
    }
   ],
   "source": [
    "datadf = shuffle(datadf)\n",
    "#print(datadf.shape)\n",
    "datadf=datadf.dropna(axis=0, how='any')\n",
    "#print(datadf.shape)\n",
    "dataset_x=datadf[['0','1','2','3','4','5','6','7','8','9']]\n",
    "dataset_y=datadf['Label']\n",
    "print(dataset_y.shape)\n",
    "trainheadlines = []\n",
    "for row in range(0,len(dataset_x.index)):\n",
    "    trainheadlines.append(' '.join(str(x) for x in dataset_x.iloc[row,:]))\n",
    "print(trainheadlines[0])\n",
    "basictrain = CountVectorizer().fit_transform(trainheadlines)\n",
    "print(basictrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclf = LogisticRegression(C=1.0, penalty='l1')\\nscoring = {'accuracy': make_scorer(accuracy_score),'prec': 'precision'}\\ncv_results = cross_validate(clf.fit(X_train, y_train), X_train, y_train, scoring=scoring)\\n\""
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(basictrain, dataset_y, test_size=0.2, stratify=dataset_y)\n",
    "clf = LogisticRegression(C=1.0, penalty='l1')\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'prec': 'precision'}\n",
    "cv_results = cross_validate(clf.fit(X_train, y_train), X_train, y_train, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [ 0.12803125  0.1005528   0.14609575]\n",
      "score_time [ 0.00400043  0.00200558  0.00399971]\n",
      "test_accuracy [ 0.50584416  0.49675325  0.50390117]\n",
      "train_accuracy [ 0.98830409  0.99220273  0.98928571]\n",
      "test_prec [ 0.5309842   0.52247874  0.52941176]\n",
      "train_prec [ 0.98651134  0.992       0.98594991]\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for s, r in cv_results.items():\n",
    "    print (s, r)\n",
    "\n",
    "neg = y_train[y_train == -1].count()\n",
    "pos = y_train[y_train == 1].count()\n",
    "print (neg*100/pos)\n",
    "\n",
    "neg2 = y_test[y_test == -1].count()\n",
    "pos2 = y_test[y_test == 1].count()\n",
    "print (neg2*100/pos2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "On test set: 0.548\n",
      "\n",
      "F1 score:\n",
      "On test set: 0.535\n",
      "\n",
      "\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          205  346\n",
      "1          176  428\n"
     ]
    }
   ],
   "source": [
    "traindf = datadf.iloc[:int(TrainSize*len(datadf)),:]\n",
    "testdf = datadf.iloc[int(TrainSize*len(datadf)):,:]\n",
    "clf = TrainingProcess(traindf)\n",
    "predictions = TestProcess(testdf,clf)\n",
    "\n",
    "calScores(testdf['Label'].values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
